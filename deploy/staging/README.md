# Deployment to staging environment

IMPORTANT: unless otherwise noted, everything is run as `app` user, make sure to
run the following each time you SSH into this instance (after setting up the
user account below).

```bash
sudo su app
```

## Instance setup

The base instance is provided on the USFWS Azure environment by USFWS IRTM staff
according to specifications defined separately. This guide covers setup of the
services used by the application.

### Install basic tools

```bash
sudo dnf --refresh update
sudo dnf install -y epel-release
sudo dnf install -y git vim p7zip p7zip-plugins
```

### Create swap space

```bash
sudo fallocate -l 4G /swapfile
sudo chmod 600 /swapfile
sudo mkswap /swapfile
sudo swapon /swapfile
```

Add this to `/etc/fstab`: `/swapfile none swap sw 0 0`

### Initialize data volume

The instance has a 128 GB volume provided by IRTM staff during setup. This needs
to be initialized and mounted:

se `lsblk` to list volumes; it may be listed as `sdb`

```bash
sudo mkfs -t ext4 /dev/sdb
sudo mkdir /data
sudo mount /dev/sdb /data
```

Add this to `/etc/fstab`: `/dev/sdb /data ext4 defaults,nofail`

### Install docker compose

```bash

sudo dnf install yum-utils
sudo yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo
sudo dnf install docker-ce docker-ce-cli containerd.io docker-compose-plugin
sudo systemctl start docker
sudo systemctl enable docker
```

Verify docker daemon is now running:

```bash
sudo systemctl status docker
```

### Create user and transfer ownership of main directories:

```bash
sudo groupadd --gid 1010 app
sudo useradd --uid 1010 --gid app --shell /bin/bash --create-home app
sudo usermod -aG docker app
sudo mkdir /var/www
sudo chown app:app /var/www
sudo chown app:app /data
# sudo usermod --shell /bin/bash app
```

Add current domain user to `app` group:

```bash
sudo usermod -aG app <domain user>
```

as `app` user:

create an alias for docker-compose by adding `alias docker-compose="docker compose"`
to `~/.bash_profile`.
(NOTE: this is only needed for muscle-memory; everything can use `docker compose` instead)

Setup directories and pull repositories:

```bash
mkdir /var/www/southeast
mkdir /var/www/ssa
mkdir /data/se
mkdir /data/tiles
cd ~
git clone https://github.com/astutespruce/secas-docker.git
git clone https://github.com/astutespruce/secas-blueprint.git
git clone https://github.com/astutespruce/secas-ssa.git
```

NOTE: only create `data/*` folders if they don't already exist on the attached EFS data volume.

### Environment setup

#### Setup Docker environment variables

Set up an environment file at `~/secas-docker/deploy/staging/.env`:

```
COMPOSE_PROJECT_NAME=secas
MAPBOX_ACCESS_TOKEN=<token>
API_TOKEN=<token>
API_SECRET=<secret>
LOGGING_LEVEL=INFO
REDIS_HOST=redis
SENTRY_DSN=<DSN>
SENTRY_ENV=blueprint-test.geoplatform.gov
ROOT_URL=<root URL>
ALLOWED_ORIGINS=<root URL>
MAP_RENDER_THREADS=4
MAX_JOBS=4
CUSTOM_REPORT_MAX_ACRES=50000000

TILE_DIR=/data/tiles
SE_CODE_DIR=/home/app/secas-blueprint
SSA_CODE_DIR=/home/app/secas-ssa
SE_DATA_DIR=/data/se
STATIC_DIR=/var/www
```

IMPORTANT: This file must be sourced to perform any Docker operations.

You can use `scripts/set_env.sh` to set these variables:

```bash
ENV=staging scripts/set_env.sh
```

If that doesn't work:

```bash
set -a
source ~/secas-docker/deploy/staging/.env
```

#### Setup user interface environment variables

Create `~/secas-blueprint/ui/.env.production` with the following:

```bash
GATSBY_MAPBOX_API_TOKEN=<mapbox token>
GATSBY_SENTRY_DSN=<dsn>
GATSBY_GOOGLE_ANALYTICS_ID=<id>
GATSBY_API_TOKEN=<api token>

SITE_ROOT_PATH=southeast
# specific to domain where this is deployed
SITE_URL=<root URL>/southeast
GATSBY_API_HOST=<root URL>/southeast
GATSBY_TILE_HOST=<root URL>
```

Create `~/secas-ssa/ui/.env.production` with the following:

```bash
GATSBY_SENTRY_DSN=<dsn>
GATSBY_GOOGLE_ANALYTICS_ID=<id>
GATSBY_API_TOKEN=<api token>

SITE_ROOT_PATH=ssa
SITE_URL=<root URL>/ssa
GATSBY_API_HOST=<root URL>/ssa
```

## Upload data

Use 7zip to zip the following directories in the `secas-blueprint` project:

-   `data/inputs`
-   `data/results`
-   `tiles`

and the following in the `secas-ssa` project:

-   `data/inputs`

Upload these to the USFWS FileShare, and then download from there to the
instance as the `app` user:

```bash
cd /data/se
curl -L -o inputs.7z <URL on fileshare>
7z e -spf inputs.7z
curl -L -o results.7z <URL on fileshare>
7z e -spf results.7z
curl -L -o inputs-ssa.7z <URL on fileshare>
7z e -spf inputs-ssa.7z
cd /data
curl -L -o tiles.7z <URL on fileshare>
7z e -spf tiles.7z
```

IMPORTANT: replace `/s/` in the URL generated by USFWS FileShare with `/shared/static`
or go into Link Settings when creating the download URL for the item in USFWS
FileShare and copy the Direct Link at the bottom.

Note: do this in a separate folder and move files if the above directories already
exist and data files have previously been downloaded to the server.

After upload, change permissions using the default user when you SSH to the
server (not the `app` user):

```
sudo chown -R app:app /data
```

## Update Docker images on the server

Pull images in this folder:

```bash
cd ~/secas-docker/deploy/staging
docker compose pull
```

Then bring the services up:

```bash
docker compose up -d
```

Make sure that each service started and is healthy.

```bash
docker compose ps
```

should show that `State` is `Up` for each of the Docker containers.

If there are problems, you can use

```bash
docker compose logs --tail 100 <service>
```

## Update API / backend code

### Southeast Blueprint Explorer

To update API / backend code for the Southeast Blueprint Explorer:

```bash
cd ~/secas-blueprint
git pull origin
cd ~/secas-docker/deploy/staging
set -a
source .env
docker compose restart se-worker se-api
```

Then verify the services came up properly:

```bash
docker compose logs --tail se-worker
docker compose logs --tail se-api
```

### Species Landscape Status Assessment Tool

To update API / backend code for the Species Landscape Status Assessment Tool:

```bash
cd ~/secas-ssa
git pull origin
cd ~/secas-docker/deploy/staging
set -a
source .env
docker compose restart ssa-worker ssa-api
```

Then verify the services came up properly:

```bash
docker compose logs --tail ssa-worker
docker compose logs --tail ssa-api
```

## Update user interface code and build it

The UI needs to be rebuilt anytime there is an update to the user interface
code for either of the applications. The build step automatically updates the
environment to use the Javascript package versions specified in the
`package-lock.json` files in each app's `ui` folder.

If needed, pull the latest UI build image from the root of this repository:

```bash
cd ~/secas-docker
docker compose -f docker/ui/docker-compose.yml pull
```

### Southeast Blueprint Explorer

To rebuild the frontend for the Southeast Blueprint Explorer:

```bash
cd ~/secas-blueprint
git pull origin
cd ~/secas-docker
set -a
source ~/secas-docker/deploy/staging/.env
scripts/build_se_ui.sh
```

### Species Landscape Status Assessment Tool

To rebuild the frontend for the Species Landscape Status Assessment Tool:

```bash
cd ~/secas-ssa
git pull origin
cd ~/secas-docker
set -a
source ~/secas-docker/deploy/staging/.env
scripts/build_ssa_ui.sh
```

## Verify applications are operating properly

Go to the following URLs and verify that they are online and functioning
properly:

-   https://blueprint-test.geoplatform.gov/southeast/
-   https://blueprint-test.geoplatform.gov/ssa/
